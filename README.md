<div align="center">

# ğŸ‘¨â€ğŸ³ Chef IA: Generador de Recetas Inteligente

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/Backend-FastAPI-009688?logo=fastapi&logoColor=white)
![Next.js](https://img.shields.io/badge/Frontend-Next.js-black?logo=next.js&logoColor=white)
![Docker](https://img.shields.io/badge/Deploy-Docker-2496ED?logo=docker&logoColor=white)
![Gemini](https://img.shields.io/badge/AI-Google%20Gemini-8E75B2?logo=google&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-yellow)

**Sistema Full Stack para la generaciÃ³n de recetas mediante Inteligencia Artificial Generativa.**
**Arquitectura de microservicios contenerizada.**

[Ver DocumentaciÃ³n](http://localhost:8000/docs) â€¢ [Reportar Bug](https://github.com/meferal/proyecto_data_engineering/issues/new?labels=bug) â€¢ [Solicitar Feature](https://github.com/meferal/proyecto_data_engineering/issues/new?labels=enhancement)

</div>

---

## ğŸ“– DescripciÃ³n

Este proyecto consiste en una aplicaciÃ³n completa (**Data Engineer**) que operacionaliza un Modelo de Lenguaje Grande (LLM) para generar recetas de cocina creativas basadas en ingredientes limitados.

El sistema implementa una arquitectura de microservicios contenerizada, con persistencia de datos y una interfaz de usuario moderna, diseÃ±ada para ser escalable y desplegable en la nube.

## ğŸš€ CaracterÃ­sticas Principales

* **GeneraciÃ³n con GenAI:** IntegraciÃ³n con **Google Gemini 1.5 Pro** para la generaciÃ³n de texto creativo.
* **Arquitectura Desacoplada:** Backend (FastAPI) y Frontend (Next.js) separados.
* **Persistencia de Datos:** Historial de peticiones guardado automÃ¡ticamente en base de datos SQL mediante **SQLAlchemy**.
* **API REST Documentada:** Endpoints accesibles y documentados automÃ¡ticamente con Swagger UI.
* **Interfaz Moderna:** Frontend desarrollado con Next.js, Tailwind CSS y renderizado de Markdown.
* **ContenerizaciÃ³n:** ImÃ¡genes de Docker optimizadas (Multi-stage builds) y orquestaciÃ³n con Docker Compose.

---

## ğŸ› ï¸ Tech Stack

### Backend
* **Lenguaje:** Python 3.11
* **Framework:** FastAPI
* **ORM:** SQLAlchemy
* **Base de Datos:** SQLite (Entorno Local) / PostgreSQL (ProducciÃ³n)
* **LLM Provider:** Google Generative AI (Gemini)
* **ValidaciÃ³n:** Pydantic

### Frontend
* **Framework:** Next.js 14 (App Router)
* **Estilos:** Tailwind CSS v3
* **Lenguaje:** TypeScript
* **Componentes:** React Markdown

### DevOps & Infraestructura
* **Contenedores:** Docker & Docker Compose
* **Nube:** Render

---

## ğŸ“‚ Estructura del Proyecto

```text
proyecto_data_engineering/
â”œâ”€â”€ app/                        # LÃ³gica del Backend (Python)
â”‚   â”œâ”€â”€ api/                    # Rutas y controladores
â”‚   â”œâ”€â”€ core/                   # ConfiguraciÃ³n y variables de entorno
â”‚   â”œâ”€â”€ db/                     # Modelos y conexiÃ³n a Base de Datos
â”‚   â”œâ”€â”€ services/               # LÃ³gica de conexiÃ³n con LLMs (Factory Pattern)
â”‚   â””â”€â”€ main.py                 # Punto de entrada de la API
â”œâ”€â”€ frontend/                   # AplicaciÃ³n Web (Next.js)
â”‚   â”œâ”€â”€ app/                    # PÃ¡ginas y layout
â”‚   â”œâ”€â”€ public/                 # Assets estÃ¡ticos
â”‚   â”œâ”€â”€ Dockerfile              # ConstrucciÃ³n multi-etapa del Frontend
â”‚   â””â”€â”€ tailwind.config.ts      # ConfiguraciÃ³n de estilos
â”œâ”€â”€ Dockerfile                  # ConstrucciÃ³n del Backend
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt            # Dependencias de Python
â”œâ”€â”€ historial.db                # Base de datos donde se almacena el historial de conversaciÃ³n
â”œâ”€â”€ LICENSE                     # Licencia MIT
â””â”€â”€ README.md                   # DocumentaciÃ³n
```

## âš¡ GuÃ­a de Inicio RÃ¡pido (Local)  

Prerrequisitos
Docker Desktop instalado y corriendo.

Una API Key de Google Gemini (Gratuita en Google AI Studio).

1. Clonar el repositorio  

```Bash
git clone [https://github.com/Meferal/Proyecto_Data_Engineering.git](https://github.com/Meferal/Proyecto_Data_Engineering.git)
cd proyecto-chef-ia
```

2. Configurar Variables de Entorno
Crea un archivo .env en la raÃ­z del proyecto y aÃ±ade tu clave:

```Bash
GEMINI_API_KEY=tu_clave_secreta_aqui
LLM_PROVIDER=gemini
```

3. Desplegar con Docker
Ejecuta el siguiente comando para construir y levantar los servicios:

```Bash
docker-compose up --build
```

4. Acceder a la AplicaciÃ³n

* Frontend (Web): http://localhost:3000

* Backend (DocumentaciÃ³n API): http://localhost:8000/docs


## ğŸ“¡ DocumentaciÃ³n de la API  

La API cuenta con los siguientes endpoints principales:

POST /api/generar  
EnvÃ­a ingredientes y recibe una receta completa.

Body: {"ingredientes": "pollo, arroz, limÃ³n"}

Respuesta: JSON con la receta formateada en Markdown.

GET /api/historial
Devuelve el listado de las Ãºltimas recetas generadas y guardadas en la base de datos.

## â˜ï¸ Despliegue en Cloud (Render)

Este proyecto estÃ¡ configurado para desplegarse automÃ¡ticamente en Render.

Backend: Se despliega como un Web Service usando el Dockerfile de la raÃ­z.

Variable de entorno requerida: GEMINI_API_KEY.

Frontend: Se despliega como un Web Service usando el Dockerfile dentro de la carpeta /frontend.

Variable de entorno requerida: NEXT_PUBLIC_API_URL (La URL que Render asigna a tu backend).

## ğŸ§‘â€ğŸ’» Autores

Proyecto realizado por:

-**Ãlvaro Medina FernÃ¡ndez [LinkedIn](http://www.linkedin.com/in/Ã¡lvaro-medinafernÃ¡ndez) | [GitHub](https://github.com/Meferal)**  

Bajo la supervisiÃ³n de **Borja Barber [GitHub](https://github.com/borjabarber)** , *Lead Instructor en The Bridge*.

---

ğŸ“œ Licencia
Este proyecto se distribuye bajo la licencia MIT. Consulta el archivo LICENSE para mÃ¡s detalles.
